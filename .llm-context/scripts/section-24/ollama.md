# Ollama Context

## Basic Information

- **Name**: Ollama
- **Slug**: ollama
- **Categories**: 20

## Description

Ollama is a tool that allows you to run large language models locally on your own computer. This means you can experiment with and use these AI models without needing an internet connection or relying on cloud-based services. It simplifies the process of managing and running these models, offering a

## Resources by Install Method

### Default Install
- **CPU**: 4 cores
- **RAM**: 4096 MB (4.0 GB)
- **Disk**: 35 GB
- **OS**: Ubuntu 24.04
- **Privileged**: true
- **Updateable**: Yes

## Access Information

- **Interface Port**: 11434
- **Web URL**: https://ollama.com/
- **Documentation**: https://github.com/ollama/ollama/tree/main/docs
- **Configuration Path**: /usr/local/lib/ollama


## Special Requirements

- **GPU Passthrough**: Required for this service

## OS Support

- **Debian 12/13**: Full package ecosystem, best compatibility
- **Ubuntu 22.04/24.04**: Latest software, 9-month support cycle
